{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. ENV setup\n",
    "\n",
    "Setup libraries and dependent data files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required notebooks\n",
    "#import import_ipynb\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Variable setup\n",
    "\n",
    "Setting up the variable values for the entire program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the variable for preparing the model\n",
    "only_start = False\n",
    "max_vocab_length = 15000\n",
    "max_length = 20\n",
    "test_split = 0.2\n",
    "random_seed = 42\n",
    "data_subset = -1\n",
    "embedding_output_dimension = 128\n",
    "lstm_units = 400\n",
    "stacked_lstm_units = 256\n",
    "dropout_rate = 0.2\n",
    "epoch = 50\n",
    "sparse_loss_fun = 'sparse_categorical_crossentropy'\n",
    "one_hot_loss_fuc = 'categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing\n",
    "\n",
    "preparing the datasets for model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from ./data/movie_titles_metadata.txt and converted into 618 lines\n",
      "Data read from ./data/movie_conversations.txt and converted into 83098 lines\n",
      "Data read from ./data/movie_lines.txt and converted into 304714 lines\n"
     ]
    }
   ],
   "source": [
    "# Load the data \n",
    "# Load the movie details meta data\n",
    "movie_titles = data_utils.load_data(file_name='movie_titles_metadata.txt')\n",
    "\n",
    "# Load the conversation meta data\n",
    "movie_conversations = data_utils.load_data(file_name='movie_conversations.txt')\n",
    "\n",
    "# Load the conversation lines\n",
    "movie_lines = data_utils.load_data(file_name='movie_lines.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(618, 83098, 304714)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_titles), len(movie_conversations), len(movie_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dictionary for all data\n",
    "movie_title_list, movie_conversation_list, movie_lines_list = data_utils.prepare_data(movie_titles=movie_titles, movie_conversations=movie_conversations, movie_lines=movie_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(617, 83097, 304713)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_title_list), len(movie_conversation_list), len(movie_lines_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movie_title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movie_conversation_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movie_lines_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataframe from  the dictionary\n",
    "movie_title_df = data_utils.dataframe_from_dict(data_dict_list=movie_title_list)\n",
    "movie_conversation_df = data_utils.dataframe_from_dict(data_dict_list=movie_conversation_list)\n",
    "movie_lines_df = data_utils.dataframe_from_dict(data_dict_list=movie_lines_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>rating</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m0</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>1999</td>\n",
       "      <td>6.90</td>\n",
       "      <td>[comedy, romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m1</td>\n",
       "      <td>1492: conquest of paradise</td>\n",
       "      <td>1992</td>\n",
       "      <td>6.20</td>\n",
       "      <td>[adventure, biography, drama, history]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m2</td>\n",
       "      <td>15 minutes</td>\n",
       "      <td>2001</td>\n",
       "      <td>6.10</td>\n",
       "      <td>[action, crime, drama, thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m3</td>\n",
       "      <td>2001: a space odyssey</td>\n",
       "      <td>1968</td>\n",
       "      <td>8.40</td>\n",
       "      <td>[adventure, mystery, sci-fi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m4</td>\n",
       "      <td>48 hrs.</td>\n",
       "      <td>1982</td>\n",
       "      <td>6.90</td>\n",
       "      <td>[action, comedy, crime, drama, thriller]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_id                        name  year rating  \\\n",
       "0       m0  10 things i hate about you  1999   6.90   \n",
       "1       m1  1492: conquest of paradise  1992   6.20   \n",
       "2       m2                  15 minutes  2001   6.10   \n",
       "3       m3       2001: a space odyssey  1968   8.40   \n",
       "4       m4                     48 hrs.  1982   6.90   \n",
       "\n",
       "                                      genre  \n",
       "0                         [comedy, romance]  \n",
       "1    [adventure, biography, drama, history]  \n",
       "2          [action, crime, drama, thriller]  \n",
       "3              [adventure, mystery, sci-fi]  \n",
       "4  [action, comedy, crime, drama, thriller]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_title_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker1</th>\n",
       "      <th>speaker2</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>line_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>[L194, L195, L196, L197]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>[L198, L199]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>[L200, L201, L202, L203]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>[L204, L205, L206]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>[L207, L208]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  speaker1 speaker2 movie_id                  line_ids\n",
       "0       u0       u2       m0  [L194, L195, L196, L197]\n",
       "1       u0       u2       m0              [L198, L199]\n",
       "2       u0       u2       m0  [L200, L201, L202, L203]\n",
       "3       u0       u2       m0        [L204, L205, L206]\n",
       "4       u0       u2       m0              [L207, L208]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_conversation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>character</th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1045</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>They do not!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1044</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>They do to!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L985</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I hope so.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L984</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>She okay?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L925</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Let's go.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  line_id speaker movie_id character      dialogue\n",
       "0   L1045      u0       m0    BIANCA  They do not!\n",
       "1   L1044      u2       m0   CAMERON   They do to!\n",
       "2    L985      u0       m0    BIANCA    I hope so.\n",
       "3    L984      u2       m0   CAMERON     She okay?\n",
       "4    L925      u0       m0    BIANCA     Let's go."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_lines_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre dictionary prepared\n"
     ]
    }
   ],
   "source": [
    "# Prepare genre dictionary\n",
    "genre_dict = data_utils.get_genre_dict(movie_title_df=movie_title_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#genre_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversations prepared\n"
     ]
    }
   ],
   "source": [
    "# Make dialogue dict for final dataset\n",
    "dialogue_dict, conversation_data_df = data_utils.prepare_conversations(movie_lines_df=movie_lines_df, movie_conversation_df=movie_conversation_df, only_start=only_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dialogue_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m0</td>\n",
       "      <td>Can we make this quick?  Roxanne Korrine and A...</td>\n",
       "      <td>Well, I thought we'd start with pronunciation,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m0</td>\n",
       "      <td>Well, I thought we'd start with pronunciation,...</td>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m0</td>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "      <td>Okay... then how 'bout we try out some French ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m0</td>\n",
       "      <td>You're asking me out.  That's so cute. What's ...</td>\n",
       "      <td>Forget it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m0</td>\n",
       "      <td>No, no, it's my fault -- we didn't have a prop...</td>\n",
       "      <td>Cameron.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_id                                              input  \\\n",
       "0       m0  Can we make this quick?  Roxanne Korrine and A...   \n",
       "1       m0  Well, I thought we'd start with pronunciation,...   \n",
       "2       m0  Not the hacking and gagging and spitting part....   \n",
       "3       m0  You're asking me out.  That's so cute. What's ...   \n",
       "4       m0  No, no, it's my fault -- we didn't have a prop...   \n",
       "\n",
       "                                              target  \n",
       "0  Well, I thought we'd start with pronunciation,...  \n",
       "1  Not the hacking and gagging and spitting part....  \n",
       "2  Okay... then how 'bout we try out some French ...  \n",
       "3                                         Forget it.  \n",
       "4                                           Cameron.  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do cleaning of the text data\n",
    "conversation_data_df['input'] = conversation_data_df['input'].apply(data_utils.clean_text)\n",
    "conversation_data_df['target'] = conversation_data_df['target'].apply(data_utils.clean_text, add_tags=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m0</td>\n",
       "      <td>can we make this quick roxanne korrine and and...</td>\n",
       "      <td>START_ well i thought we would start with pron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m0</td>\n",
       "      <td>well i thought we would start with pronunciati...</td>\n",
       "      <td>START_ not the hacking and gagging and spittin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m0</td>\n",
       "      <td>not the hacking and gagging and spitting part ...</td>\n",
       "      <td>START_ okay then how bout we try out some fren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m0</td>\n",
       "      <td>you are asking me out that is so cute what is ...</td>\n",
       "      <td>START_ forget it _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m0</td>\n",
       "      <td>no no its my fault we did not have a proper in...</td>\n",
       "      <td>START_ cameron _END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_id                                              input  \\\n",
       "0       m0  can we make this quick roxanne korrine and and...   \n",
       "1       m0  well i thought we would start with pronunciati...   \n",
       "2       m0  not the hacking and gagging and spitting part ...   \n",
       "3       m0  you are asking me out that is so cute what is ...   \n",
       "4       m0  no no its my fault we did not have a proper in...   \n",
       "\n",
       "                                              target  \n",
       "0  START_ well i thought we would start with pron...  \n",
       "1  START_ not the hacking and gagging and spittin...  \n",
       "2  START_ okay then how bout we try out some fren...  \n",
       "3                              START_ forget it _END  \n",
       "4                                START_ cameron _END  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>221616</td>\n",
       "      <td>221616</td>\n",
       "      <td>221616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>617</td>\n",
       "      <td>187664</td>\n",
       "      <td>187033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>m289</td>\n",
       "      <td>what</td>\n",
       "      <td>START_ what _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1192</td>\n",
       "      <td>1732</td>\n",
       "      <td>1601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       movie_id   input            target\n",
       "count    221616  221616            221616\n",
       "unique      617  187664            187033\n",
       "top        m289    what  START_ what _END\n",
       "freq       1192    1732              1601"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_data_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33% filtered from original data\n"
     ]
    }
   ],
   "source": [
    "# Filtering data which are not in appropriate length\n",
    "filtered_conversation_df = data_utils.filter_short_long(conversation_data_df=conversation_data_df, \n",
    "                                                        min_q_length=2, max_q_length=20, \n",
    "                                                        min_a_length=2, max_a_length=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m0</td>\n",
       "      <td>well i thought we would start with pronunciati...</td>\n",
       "      <td>START_ not the hacking and gagging and spittin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m0</td>\n",
       "      <td>not the hacking and gagging and spitting part ...</td>\n",
       "      <td>START_ okay then how bout we try out some fren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m0</td>\n",
       "      <td>you are asking me out that is so cute what is ...</td>\n",
       "      <td>START_ forget it _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m0</td>\n",
       "      <td>no no its my fault we did not have a proper in...</td>\n",
       "      <td>START_ cameron _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m0</td>\n",
       "      <td>gosh if only we could find kat a boyfriend</td>\n",
       "      <td>START_ let me see what i can do _END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_id                                              input  \\\n",
       "0       m0  well i thought we would start with pronunciati...   \n",
       "1       m0  not the hacking and gagging and spitting part ...   \n",
       "2       m0  you are asking me out that is so cute what is ...   \n",
       "3       m0  no no its my fault we did not have a proper in...   \n",
       "4       m0         gosh if only we could find kat a boyfriend   \n",
       "\n",
       "                                              target  \n",
       "0  START_ not the hacking and gagging and spittin...  \n",
       "1  START_ okay then how bout we try out some fren...  \n",
       "2                              START_ forget it _END  \n",
       "3                                START_ cameron _END  \n",
       "4               START_ let me see what i can do _END  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_conversation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>148207</td>\n",
       "      <td>148207</td>\n",
       "      <td>148207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>617</td>\n",
       "      <td>132259</td>\n",
       "      <td>121712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>m299</td>\n",
       "      <td>i do not know</td>\n",
       "      <td>START_ what _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>789</td>\n",
       "      <td>250</td>\n",
       "      <td>1311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       movie_id          input            target\n",
       "count    148207         148207            148207\n",
       "unique      617         132259            121712\n",
       "top        m299  i do not know  START_ what _END\n",
       "freq        789            250              1311"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_conversation_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare text vectorizer object\n",
    "Vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                output_mode=\"int\",\n",
    "                                output_sequence_length=max_length,\n",
    "                                standardize=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt the text vectorizer for the dataset\n",
    "Vectorizer.adapt(filtered_conversation_df['target'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = Vectorizer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorizer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare traing and test datasets from subset of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only the comedy movies data\n",
    "comedy_movies_list = genre_dict['comedy']\n",
    "\n",
    "comedy_movie_line_df = filtered_conversation_df[filtered_conversation_df['movie_id'].isin(comedy_movies_list)][:data_subset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m0</td>\n",
       "      <td>well i thought we would start with pronunciati...</td>\n",
       "      <td>START_ not the hacking and gagging and spittin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m0</td>\n",
       "      <td>not the hacking and gagging and spitting part ...</td>\n",
       "      <td>START_ okay then how bout we try out some fren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m0</td>\n",
       "      <td>you are asking me out that is so cute what is ...</td>\n",
       "      <td>START_ forget it _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m0</td>\n",
       "      <td>no no its my fault we did not have a proper in...</td>\n",
       "      <td>START_ cameron _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m0</td>\n",
       "      <td>gosh if only we could find kat a boyfriend</td>\n",
       "      <td>START_ let me see what i can do _END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_id                                              input  \\\n",
       "0       m0  well i thought we would start with pronunciati...   \n",
       "1       m0  not the hacking and gagging and spitting part ...   \n",
       "2       m0  you are asking me out that is so cute what is ...   \n",
       "3       m0  no no its my fault we did not have a proper in...   \n",
       "4       m0         gosh if only we could find kat a boyfriend   \n",
       "\n",
       "                                              target  \n",
       "0  START_ not the hacking and gagging and spittin...  \n",
       "1  START_ okay then how bout we try out some fren...  \n",
       "2                              START_ forget it _END  \n",
       "3                                START_ cameron _END  \n",
       "4               START_ let me see what i can do _END  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comedy_movie_line_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>46217</td>\n",
       "      <td>46217</td>\n",
       "      <td>46217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>159</td>\n",
       "      <td>42805</td>\n",
       "      <td>39557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>m299</td>\n",
       "      <td>i do not know</td>\n",
       "      <td>START_ what _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>789</td>\n",
       "      <td>76</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       movie_id          input            target\n",
       "count     46217          46217             46217\n",
       "unique      159          42805             39557\n",
       "top        m299  i do not know  START_ what _END\n",
       "freq        789             76               416"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comedy_movie_line_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data points: 36973\n",
      "Test data points: 9244\n",
      "5% filtered from training data points\n",
      "After unknown token filters training data points: 35071\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for datasets also remove the sentences with most unknown tokens\n",
    "training_data, testing_data = data_utils.split_vectorize_filter_unk(conversation_data_df=comedy_movie_line_df, Vectorizer=Vectorizer, test_split=test_split, seed=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['input', 'target', 'input_vectors', 'target_vectors']),\n",
       " dict_keys(['input', 'target', 'input_vectors', 'target_vectors']))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.keys(), testing_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training input (35071,) <class 'list'>\n",
      "testing input (9244,) <class 'numpy.ndarray'>\n",
      "training target (35071,) <class 'list'>\n",
      "testing target (9244,) <class 'numpy.ndarray'>\n",
      "training input_vectors (35071, 20) <class 'list'>\n",
      "testing input_vectors (9244, 20) <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "training target_vectors (35071, 20) <class 'list'>\n",
      "testing target_vectors (9244, 20) <class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "for x in training_data.keys():\n",
    "    print('training', x, np.array(training_data[x]).shape, type(training_data[x]))\n",
    "    print('testing', x, np.array(testing_data[x]).shape, type(testing_data[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'those'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vectorizer.get_vocabulary()[188]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('robthanks for everything this is really happening i never thought',\n",
       " 'START_ junior year _END')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['input'][sample_index], testing_data['target'][sample_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(20,), dtype=int64, numpy=\n",
       " array([  1,  28, 214,  29,  10,  99, 819,   5,  96, 132,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0], dtype=int64)>,\n",
       " <tf.Tensor: shape=(20,), dtype=int64, numpy=\n",
       " array([1370,  459,    2,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0], dtype=int64)>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['input_vectors'][sample_index], testing_data['target_vectors'][sample_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'START_ not the hacking and gagging and spitting part please _END'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comedy_movie_line_df['target'].to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35071"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data['target_vectors'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input', 'target', 'input_vectors', 'target_vectors'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 6)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.to_categorical(tf.random.uniform(shape=(2,3)), 6).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.expand_dims(tf.constant(np.array(training_data['target_vectors'])), axis = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing datasets\n",
    "train_inputs = np.array(training_data['input'])\n",
    "train_targets = np.array(training_data['target'])\n",
    "#train_vector_targets = tf.keras.utils.to_categorical(np.array(training_data['target_vectors']), max_vocab_length)\n",
    "train_vector_targets = tf.expand_dims(tf.constant(np.array(training_data['target_vectors'])), axis=-1)\n",
    "\n",
    "test_inputs = np.array(testing_data['input'])\n",
    "test_targets = np.array(testing_data['target'])\n",
    "#test_vector_targets = tf.keras.utils.to_categorical(np.array(testing_data['target_vectors']), max_vocab_length)\n",
    "test_vector_targets = tf.expand_dims(tf.constant(np.array(testing_data['target_vectors'])), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35071,), (35071,), TensorShape([35071, 20, 1]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape, train_targets.shape, train_vector_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9244,), (9244,), TensorShape([9244, 20, 1]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs.shape, test_targets.shape, test_vector_targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing dataset for training and validation\n",
    "train_data_dataset = tf.data.Dataset.from_tensor_slices((train_inputs, train_targets))\n",
    "train_lables_dataset = tf.data.Dataset.from_tensor_slices(train_vector_targets)\n",
    "train_dataset = tf.data.Dataset.zip((train_data_dataset, train_lables_dataset))\n",
    "train_dataset = train_dataset.batch(128).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_data_dataset = tf.data.Dataset.from_tensor_slices((test_inputs, test_targets))\n",
    "test_lables_dataset = tf.data.Dataset.from_tensor_slices(test_vector_targets)\n",
    "test_dataset = tf.data.Dataset.zip((test_data_dataset, test_lables_dataset))\n",
    "test_dataset = test_dataset.batch(128).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prepare traing and test datasets from all available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data points: 118565\n",
      "Test data points: 29642\n",
      "4% filtered from training data points\n",
      "After unknown token filters training data points: 112655\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for datasets also remove the sentences with most unknown tokens\n",
    "training_data_all, testing_data_all = data_utils.split_vectorize_filter_unk(conversation_data_df=filtered_conversation_df, Vectorizer=Vectorizer, test_split=test_split, seed=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing datasets\n",
    "train_inputs_all = np.array(training_data_all['input'])\n",
    "train_targets_all = np.array(training_data_all['target'])\n",
    "#train_vector_targets_all = tf.keras.utils.to_categorical(np.array(training_data_all['target_vectors']), max_vocab_length)\n",
    "train_vector_targets_all = tf.expand_dims(tf.constant(np.array(training_data_all['target_vectors'])), axis=-1)\n",
    "\n",
    "test_inputs_all = np.array(testing_data_all['input'])\n",
    "test_targets_all = np.array(testing_data_all['target'])\n",
    "#test_vector_targets_all = tf.keras.utils.to_categorical(np.array(testing_data_all['target_vectors']), max_vocab_length)\n",
    "test_vector_targets_all = tf.expand_dims(tf.constant(np.array(testing_data_all['target_vectors'])), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing dataset for training and validation\n",
    "train_data_dataset_all = tf.data.Dataset.from_tensor_slices((train_inputs_all, train_targets_all))\n",
    "train_lables_dataset_all = tf.data.Dataset.from_tensor_slices(train_vector_targets_all)\n",
    "train_dataset_all = tf.data.Dataset.zip((train_data_dataset_all, train_lables_dataset_all))\n",
    "train_dataset_all = train_dataset_all.batch(128).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_data_dataset_all = tf.data.Dataset.from_tensor_slices((test_inputs_all, test_targets_all))\n",
    "test_lables_dataset_all = tf.data.Dataset.from_tensor_slices(test_vector_targets_all)\n",
    "test_dataset_all = tf.data.Dataset.zip((test_data_dataset_all, test_lables_dataset_all))\n",
    "test_dataset_all = test_dataset_all.batch(128).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4 with dual layer lstm (all data)\n",
    "\n",
    "* Input for this model is string (question, answer first word(START_))\n",
    "* Output will be the probability of the next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creatimg embedding objects for encoder and decoder models\n",
    "EncoderEmbeddingLayerM4 = tf.keras.layers.Embedding(input_dim=max_vocab_length,\n",
    "                                     output_dim=embedding_output_dimension,\n",
    "                                     input_length=max_length,\n",
    "                                     mask_zero=True,\n",
    "                                     name='encoder_embedding_layer_model4')\n",
    "\n",
    "DecoderEmbeddingLayerM4 = tf.keras.layers.Embedding(input_dim=max_vocab_length,\n",
    "                                     output_dim=embedding_output_dimension,\n",
    "                                     input_length=max_length,\n",
    "                                     mask_zero=True,\n",
    "                                     name='decoder_embedding_layer_model4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create encoder & decoder initial layers\n",
    "EncoderInputM4 = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
    "encoder_vectorM4 = Vectorizer(EncoderInputM4)\n",
    "\n",
    "DecoderInputM4 = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
    "decoder_vectorM4 = Vectorizer(DecoderInputM4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create encoder\n",
    "encoder_embeddings_M4 = EncoderEmbeddingLayerM4(encoder_vectorM4)\n",
    "\n",
    "EncoderLstmLayer1M4 = tf.keras.layers.LSTM(stacked_lstm_units, return_state=True, return_sequences=True, name='Encoder_LSTM_layer1_model4')\n",
    "encoder_outputs_layer1_M4, state_h_layer1_M4, state_c_layer1_M4 = EncoderLstmLayer1M4(encoder_embeddings_M4)\n",
    "encoder_states_layer1_M4 = [state_h_layer1_M4, state_c_layer1_M4]\n",
    "\n",
    "EncoderLstmLayer2M4 = tf.keras.layers.LSTM(stacked_lstm_units, return_state=True, name='Encoder_LSTM2_layer2_model4')\n",
    "encoder_outputs_layer2_M4, state_h_layer2_M4, state_c_layer2_M4 = EncoderLstmLayer2M4(encoder_outputs_layer1_M4)\n",
    "encoder_states_layer2_M4 = [state_h_layer2_M4, state_c_layer2_M4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create decoder\n",
    "decoder_embeddings_M4 = DecoderEmbeddingLayerM4(decoder_vectorM4)\n",
    "\n",
    "DecoderLstmLayer1M4 = tf.keras.layers.LSTM(stacked_lstm_units, return_sequences=True, return_state=True, name='Decoder_LSTM2_layer1_model4')\n",
    "decoder_outputs_layer1_M4, _, _ = DecoderLstmLayer1M4(decoder_embeddings_M4, initial_state=encoder_states_layer1_M4)\n",
    "\n",
    "DecoderLstmLayer2M4 = tf.keras.layers.LSTM(stacked_lstm_units, return_sequences=True, return_state=True, name='Decoder_LSTM2_layer2_model4')\n",
    "decoder_outputs_layer2_M4, _, _ = DecoderLstmLayer2M4(decoder_outputs_layer1_M4, initial_state=encoder_states_layer2_M4)\n",
    "\n",
    "DecoderDenseLayerM4 = tf.keras.layers.Dense(max_vocab_length, activation='softmax', name='Decoder_Dense_layer_model4')\n",
    "decoder_dense_outputs_M4 = DecoderDenseLayerM4(decoder_outputs_layer2_M4)\n",
    "\n",
    "EncDecModel4 = tf.keras.Model([EncoderInputM4, DecoderInputM4], decoder_dense_outputs_M4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "EncDecModel4.compile(loss=sparse_loss_fun,\n",
    "                    optimizer=tf.keras.optimizers.Adam(),\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder at test time\n",
    "EncModel4 = tf.keras.Model(EncoderInputM4, [encoder_states_layer1_M4, encoder_states_layer2_M4])\n",
    "\n",
    "DecoderStateInputHLayer1M4 = tf.keras.layers.Input(shape=(stacked_lstm_units,))\n",
    "DecoderStateInputCLayer1M4 = tf.keras.layers.Input(shape=(stacked_lstm_units,))\n",
    "decoder_states_inputs_layer1_M4 = [DecoderStateInputHLayer1M4, DecoderStateInputCLayer1M4]\n",
    "\n",
    "DecoderStateInputHLayer2M4 = tf.keras.layers.Input(shape=(stacked_lstm_units,))\n",
    "DecoderStateInputCLayer2M4 = tf.keras.layers.Input(shape=(stacked_lstm_units,))\n",
    "decoder_states_inputs_layer2_M4 = [DecoderStateInputHLayer2M4, DecoderStateInputCLayer2M4]\n",
    "\n",
    "decoder_vector_test_M4 = Vectorizer(DecoderInputM4)\n",
    "dec_embedding_test_M4 = DecoderEmbeddingLayerM4(decoder_vector_test_M4)\n",
    "\n",
    "decoder_lstm_outputs_test_layer1_M4, state_h_test_layer1_M4, state_c_test_layer1_M4 = DecoderLstmLayer1M4(dec_embedding_test_M4, initial_state=decoder_states_inputs_layer1_M4)\n",
    "decoder_states_test_layer1_M4 = [state_h_test_layer1_M4, state_c_test_layer1_M4]\n",
    "\n",
    "decoder_lstm_outputs_test_layer2_M4, state_h2_test_layer2, state_c2_test_layer2 = DecoderLstmLayer2M4(decoder_lstm_outputs_test_layer1_M4, initial_state=decoder_states_inputs_layer2_M4)\n",
    "decoder_states_test_layer2_M4 = [state_h2_test_layer2, state_c2_test_layer2]\n",
    "\n",
    "decoder_dense_outputs_test_M4 = DecoderDenseLayerM4(decoder_lstm_outputs_test_layer2_M4)\n",
    "\n",
    "DecModel4 = tf.keras.Model(\n",
    "    inputs = [DecoderInputM4, [decoder_states_inputs_layer1_M4, decoder_states_inputs_layer2_M4]],\n",
    "    outputs = [decoder_dense_outputs_test_M4] + [decoder_states_test_layer1_M4, decoder_states_test_layer2_M4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " text_vectorization (TextVector  (None, 20)          0           ['input_1[0][0]',                \n",
      " ization)                                                         'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " encoder_embedding_layer_model4  (None, 20, 128)     1920000     ['text_vectorization[0][0]']     \n",
      "  (Embedding)                                                                                     \n",
      "                                                                                                  \n",
      " decoder_embedding_layer_model4  (None, 20, 128)     1920000     ['text_vectorization[1][0]']     \n",
      "  (Embedding)                                                                                     \n",
      "                                                                                                  \n",
      " Encoder_LSTM_layer1_model4 (LS  [(None, 20, 256),   394240      ['encoder_embedding_layer_model4[\n",
      " TM)                             (None, 256),                    0][0]']                          \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " Decoder_LSTM2_layer1_model4 (L  [(None, 20, 256),   394240      ['decoder_embedding_layer_model4[\n",
      " STM)                            (None, 256),                    0][0]',                          \n",
      "                                 (None, 256)]                     'Encoder_LSTM_layer1_model4[0][1\n",
      "                                                                 ]',                              \n",
      "                                                                  'Encoder_LSTM_layer1_model4[0][2\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " Encoder_LSTM2_layer2_model4 (L  [(None, 256),       525312      ['Encoder_LSTM_layer1_model4[0][0\n",
      " STM)                            (None, 256),                    ]']                              \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " Decoder_LSTM2_layer2_model4 (L  [(None, 20, 256),   525312      ['Decoder_LSTM2_layer1_model4[0][\n",
      " STM)                            (None, 256),                    0]',                             \n",
      "                                 (None, 256)]                     'Encoder_LSTM2_layer2_model4[0][\n",
      "                                                                 1]',                             \n",
      "                                                                  'Encoder_LSTM2_layer2_model4[0][\n",
      "                                                                 2]']                             \n",
      "                                                                                                  \n",
      " Decoder_Dense_layer_model4 (De  (None, 20, 15000)   3855000     ['Decoder_LSTM2_layer2_model4[0][\n",
      " nse)                                                            0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,534,104\n",
      "Trainable params: 9,534,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EncDecModel4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x19eb7116490>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EncDecModel4.load_weights('model_weights/2LayerLstmAllData50epochs/EncDecModel4Weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_history4 = EncDecModel4.fit(train_dataset_all,\n",
    "#                epochs=epoch,\n",
    "#                validation_data=test_dataset_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i was sent from the post in place of our social editor',\n",
       "       'move it', 'but darling you ca not do that',\n",
       "       'i am just yknow passing the time best i can till i can see you',\n",
       "       'she is still a transvestite',\n",
       "       'yeah well it was really all kind of a joke and a ripoff so uhso i dropped out',\n",
       "       'yes master', 'what what is it all about',\n",
       "       'i dunno but they look nice i rather like em', 'where is karen'],\n",
       "      dtype='<U149')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs_all[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['START_ yes of course miss ramsey telephoned me well what would you like to have _END',\n",
       "       'START_ where _END', 'START_ comrades good people of france _END',\n",
       "       'START_ god i ca not believe i ever hated you _END',\n",
       "       'START_ mm _END', 'START_ oh that is too bad _END',\n",
       "       'START_ live ones where only the dead should be _END',\n",
       "       'START_ huh do you mind if i sit down i am carrying quite a load here _END',\n",
       "       'START_ top of the list of priorities how nice they look _END',\n",
       "       'START_ in the can that the money _END'], dtype='<U135')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets_all[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_model4_test(input_word: str, states: list, vocab_list: list):\n",
    "    decoder_vector_test_M4 = Vectorizer([input_word])\n",
    "    dec_embedding_test_M4 = DecoderEmbeddingLayerM4(decoder_vector_test_M4)\n",
    "    decoder_lstm_outputs_test_layer1_M4, state_h_l1_M4, state_c_l1_M4 = DecoderLstmLayer1M4(dec_embedding_test_M4, initial_state=states[0])\n",
    "    decoder_lstm_outputs_test_layer2_M4, state_h_l2_M4, state_c_l2_M4 = DecoderLstmLayer2M4(decoder_lstm_outputs_test_layer1_M4, initial_state=states[1])\n",
    "    decoder_dense_outputs_test_M4 = DecoderDenseLayerM4(decoder_lstm_outputs_test_layer2_M4)\n",
    "    word_idx = tf.argmax(decoder_dense_outputs_test_M4[0, 0, :]).numpy()\n",
    "    next_word = vocab_list[word_idx]\n",
    "    states[0] = [tf.constant(state_h_l1_M4), tf.constant(state_c_l1_M4)]\n",
    "    states[1] = [tf.constant(state_h_l2_M4), tf.constant(state_c_l2_M4)]\n",
    "    return next_word, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human:  Hi\n",
      "KATTA: hello \n",
      "Human:  How are you\n",
      "KATTA: all right \n",
      "Human:  what are you doing\n",
      "KATTA: i am thinking \n",
      "Human:  good\n",
      "KATTA: well i got something to do with it \n",
      "Human:  do you need any help\n",
      "KATTA: i do not think i am \n",
      "Human:  are you a robot\n",
      "KATTA: no \n",
      "Human:  are you a human\n",
      "KATTA: yes \n",
      "Human:  do you know me\n",
      "KATTA: yes \n",
      "Human:  where are you\n",
      "KATTA: i am here \n",
      "Human:  who are you\n",
      "KATTA: gondorff asked me to meet you \n",
      "Human:  do you want to say anything\n",
      "KATTA: no \n",
      "Human:  okay great\n",
      "KATTA: you are not \n",
      "Human:  do you like me\n",
      "KATTA: it was not me \n",
      "Human:  good night\n",
      "KATTA: good night \n",
      "Human:  what's your name\n",
      "KATTA: [UNK] morton \n",
      "Human:  okay good bye\n",
      "KATTA: hey \n",
      "Human:  what\n",
      "KATTA: do not let me go \n",
      "Human:  goodbye\n",
      "KATTA: alright \n",
      "Human:  END CONVO\n",
      "KATTA: threatening me \n"
     ]
    }
   ],
   "source": [
    "end_convo = True\n",
    "while end_convo:\n",
    "  human = input(\"Human: \")\n",
    "  print('Human: ', human)\n",
    "  if human == 'END CONVO':\n",
    "    end_convo = False\n",
    "  bot_response = data_utils.make_prediction(vocab_list=vocab_list, decoder_model_function=decoder_model4_test, encoder_model=EncModel4, input_text=human, clean_text=data_utils.clean_text, multi_layer=True)\n",
    "  print(\"KATTA:\", bot_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Human:  Hi\n",
    "KATTA: hello \n",
    "Human:  How are you\n",
    "KATTA: all right \n",
    "Human:  what are you doing\n",
    "KATTA: i am thinking \n",
    "Human:  good\n",
    "KATTA: well i got something to do with it \n",
    "Human:  do you need any help\n",
    "KATTA: i do not think i am \n",
    "Human:  are you a robot\n",
    "KATTA: no \n",
    "Human:  are you a human\n",
    "KATTA: yes \n",
    "Human:  do you know me\n",
    "KATTA: yes \n",
    "Human:  where are you\n",
    "KATTA: i am here \n",
    "Human:  who are you\n",
    "KATTA: gondorff asked me to meet you \n",
    "Human:  do you want to say anything\n",
    "KATTA: no \n",
    "Human:  okay great\n",
    "KATTA: you are not \n",
    "Human:  do you like me\n",
    "KATTA: it was not me \n",
    "Human:  good night\n",
    "KATTA: good night \n",
    "Human:  what's your name\n",
    "KATTA: [UNK] morton \n",
    "Human:  okay good bye\n",
    "KATTA: hey \n",
    "Human:  what\n",
    "KATTA: do not let me go \n",
    "Human:  goodbye\n",
    "KATTA: alright \n",
    "Human:  END CONVO\n",
    "KATTA: threatening me \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EncDecModel.save_weights('model_weights/2LayerLstmAllData50epochs/EncDecModel4Weights')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "59274f66ba6d87f8881ad97d5dea530dfc64a2944c69a18ecfbd70818c31a586"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
